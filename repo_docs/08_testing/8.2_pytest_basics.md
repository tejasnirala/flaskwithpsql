# 8.2 Pytest Basics

> **Understanding Python's Premier Testing Framework**

This document explains pytest fundamentals for developers transitioning from JavaScript testing frameworks like Jest or Mocha.

---

## Table of Contents

1. [What is pytest?](#what-is-pytest)
2. [Jest vs pytest Comparison](#jest-vs-pytest-comparison)
3. [Writing Your First Test](#writing-your-first-test)
4. [Assertions](#assertions)
5. [Test Organization](#test-organization)
6. [Testing Exceptions](#testing-exceptions)
7. [Parametrized Tests](#parametrized-tests)
8. [Markers and Skipping](#markers-and-skipping)

---

## What is pytest?

### Overview

**pytest** is Python's most popular testing framework. It's known for:

-   Simple syntax (just use `assert`)
-   Powerful fixtures
-   Rich plugin ecosystem
-   Excellent error messages

### Installation

```bash
pip install pytest pytest-cov
```

### Minimal Example

```python
# test_example.py

def test_addition():
    assert 1 + 1 == 2

def test_string():
    assert "hello".upper() == "HELLO"
```

Run:

```bash
pytest test_example.py
```

---

## Jest vs pytest Comparison

### Test Structure

```javascript
// Jest (JavaScript)
describe("Calculator", () => {
    it("should add two numbers", () => {
        expect(add(1, 2)).toBe(3);
    });

    it("should subtract two numbers", () => {
        expect(subtract(5, 3)).toBe(2);
    });
});
```

```python
# pytest (Python)
class TestCalculator:
    def test_add_two_numbers(self):
        assert add(1, 2) == 3

    def test_subtract_two_numbers(self):
        assert subtract(5, 3) == 2
```

### Key Differences

| Feature         | Jest                | pytest                           |
| --------------- | ------------------- | -------------------------------- |
| **Assertions**  | `expect(x).toBe(y)` | `assert x == y`                  |
| **Grouping**    | `describe()` blocks | Classes or files                 |
| **Test naming** | `it()` or `test()`  | `def test_*()`                   |
| **Setup**       | `beforeEach()`      | Fixtures                         |
| **Mocking**     | `jest.mock()`       | `unittest.mock` / `pytest-mock`  |
| **Config file** | `jest.config.js`    | `pytest.ini` or `pyproject.toml` |

### Assertions Comparison

```javascript
// Jest
expect(value).toBe(3);
expect(value).not.toBe(3);
expect(array).toContain(item);
expect(fn).toThrow(Error);
expect(obj).toEqual({ a: 1 });
```

```python
# pytest
assert value == 3
assert value != 3
assert item in array
with pytest.raises(Exception): fn()
assert obj == {"a": 1}
```

---

## Writing Your First Test

### File Naming Convention

pytest automatically discovers tests in files named:

-   `test_*.py`
-   `*_test.py`

```
tests/
├── test_user.py       ✅ Will be discovered
├── user_test.py       ✅ Will be discovered
├── user_tests.py      ❌ Won't be discovered
└── test_something.py  ✅ Will be discovered
```

### Function Naming Convention

Test functions must start with `test_`:

```python
def test_something():      # ✅ Discovered
    pass

def check_something():     # ❌ Not discovered
    pass
```

### A Complete Test File

```python
# tests/test_calculator.py
"""Tests for calculator module."""

def add(a, b):
    return a + b

def divide(a, b):
    if b == 0:
        raise ValueError("Cannot divide by zero")
    return a / b


# ============================================================================
# Tests
# ============================================================================

def test_add_positive_numbers():
    """Test adding two positive numbers."""
    result = add(2, 3)
    assert result == 5

def test_add_negative_numbers():
    """Test adding negative numbers."""
    result = add(-1, -1)
    assert result == -2

def test_divide_numbers():
    """Test division."""
    result = divide(10, 2)
    assert result == 5.0

def test_divide_by_zero_raises():
    """Test that dividing by zero raises ValueError."""
    import pytest
    with pytest.raises(ValueError):
        divide(10, 0)
```

---

## Assertions

### Basic Assertions

```python
# Equality
assert value == 5
assert value != 10

# Identity
assert value is None
assert value is not None

# Truth
assert value
assert not empty_list

# Comparison
assert value > 0
assert value >= 0
assert value < 100

# Containment
assert item in collection
assert item not in collection

# Type
assert isinstance(value, int)
assert isinstance(value, (int, float))
```

### Assertion Messages

```python
# Add context with assertion messages
assert value == expected, f"Expected {expected}, got {value}"

# Example with context
def test_user_creation():
    user = create_user("john")
    assert user.username == "john", f"Username was {user.username}"
    assert user.is_active, "User should be active by default"
```

### Comparing Collections

```python
# Lists - order matters
assert [1, 2, 3] == [1, 2, 3]     # ✅
assert [1, 2, 3] == [3, 2, 1]     # ❌

# Sets - order doesn't matter
assert {1, 2, 3} == {3, 2, 1}     # ✅

# Dicts
assert {"a": 1} == {"a": 1}       # ✅
assert {"a": 1, "b": 2} == {"b": 2, "a": 1}  # ✅ (order doesn't matter)

# Approximate floats
import pytest
assert 0.1 + 0.2 == pytest.approx(0.3)
```

---

## Test Organization

### Using Classes

Group related tests in classes:

```python
class TestUserCreation:
    """Tests for user creation."""

    def test_create_user_with_valid_data(self):
        user = create_user("john", "john@example.com")
        assert user.id is not None

    def test_create_user_with_invalid_email(self):
        with pytest.raises(ValueError):
            create_user("john", "invalid-email")


class TestUserAuthentication:
    """Tests for user authentication."""

    def test_authenticate_with_correct_password(self):
        user = authenticate("john@example.com", "password123")
        assert user is not None

    def test_authenticate_with_wrong_password(self):
        with pytest.raises(InvalidCredentialsError):
            authenticate("john@example.com", "wrong")
```

### Using Modules

Or organize by file:

```
tests/
├── test_user_creation.py
├── test_user_authentication.py
├── test_user_update.py
└── test_user_deletion.py
```

---

## Testing Exceptions

### Basic Exception Testing

```python
import pytest

def test_divide_by_zero():
    """Test that ValueError is raised for division by zero."""
    with pytest.raises(ValueError):
        divide(10, 0)
```

### Checking Exception Message

```python
def test_divide_by_zero_message():
    """Test the exception message."""
    with pytest.raises(ValueError) as exc_info:
        divide(10, 0)

    assert "Cannot divide by zero" in str(exc_info.value)
```

### Checking Exception Attributes

```python
def test_user_exists_error():
    """Test UserAlreadyExistsError attributes."""
    with pytest.raises(UserAlreadyExistsError) as exc_info:
        UserService.create_user(duplicate_data)

    error = exc_info.value
    assert error.field == "email"
    assert error.value == "existing@example.com"
```

---

## Parametrized Tests

### The Problem

```python
# Repetitive tests
def test_is_even_with_2():
    assert is_even(2) is True

def test_is_even_with_4():
    assert is_even(4) is True

def test_is_even_with_6():
    assert is_even(6) is True

def test_is_even_with_3():
    assert is_even(3) is False
```

### The Solution: Parametrize

```python
import pytest

@pytest.mark.parametrize("number,expected", [
    (2, True),
    (4, True),
    (6, True),
    (3, False),
    (5, False),
    (0, True),
])
def test_is_even(number, expected):
    assert is_even(number) == expected
```

### Multiple Parameters

```python
@pytest.mark.parametrize("username,email,valid", [
    ("john", "john@example.com", True),
    ("jane", "jane@example.com", True),
    ("", "test@example.com", False),       # Empty username
    ("john", "invalid-email", False),      # Invalid email
    ("ab", "ab@example.com", False),       # Username too short
])
def test_user_validation(username, email, valid):
    if valid:
        user = create_user(username, email)
        assert user is not None
    else:
        with pytest.raises(ValidationError):
            create_user(username, email)
```

---

## Markers and Skipping

### Skip a Test

```python
import pytest

@pytest.mark.skip(reason="Not implemented yet")
def test_future_feature():
    pass

@pytest.mark.skipif(sys.platform == "win32", reason="Not supported on Windows")
def test_unix_only():
    pass
```

### Expected Failures

```python
@pytest.mark.xfail(reason="Known bug, fix pending")
def test_with_known_bug():
    assert broken_function() == expected
```

### Custom Markers

```python
# Define in pytest.ini or pyproject.toml
# [tool.pytest.ini_options]
# markers = [
#     "slow: marks test as slow",
#     "database: marks test as requiring database",
# ]

@pytest.mark.slow
def test_slow_operation():
    time.sleep(5)
    assert slow_function() == expected

@pytest.mark.database
def test_database_operation(db):
    result = db.query(...)
    assert result is not None
```

Run specific markers:

```bash
# Run only slow tests
pytest -m slow

# Run everything except slow tests
pytest -m "not slow"
```

---

## Summary

### pytest Cheat Sheet

```python
# Basic assertion
assert value == expected

# With message
assert value == expected, "Custom message"

# Exception testing
with pytest.raises(SomeError):
    risky_function()

# Approximate comparison
assert result == pytest.approx(expected, rel=1e-3)

# Parametrized test
@pytest.mark.parametrize("input,expected", [(1, 2), (2, 4)])
def test_double(input, expected):
    assert double(input) == expected

# Skip test
@pytest.mark.skip(reason="Not implemented")
def test_wip():
    pass
```

### Common Commands

| Command               | Purpose                       |
| --------------------- | ----------------------------- |
| `pytest`              | Run all tests                 |
| `pytest -v`           | Verbose output                |
| `pytest -x`           | Stop on first failure         |
| `pytest --lf`         | Run last failed tests         |
| `pytest -k "pattern"` | Run tests matching pattern    |
| `pytest -m marker`    | Run tests with marker         |
| `pytest --pdb`        | Drop into debugger on failure |

---

## Next Steps

-   **[8.3 Fixtures Explained](./8.3_fixtures_explained.md)** - Reusable test setup
-   **[8.4 Conftest File](./8.4_conftest_file.md)** - Shared fixture configuration

---

> **Related Documentation:**
>
> -   [pytest documentation](https://docs.pytest.org/)
> -   [tests/](../../tests/) - Our test suite
