# 7.3 Dockerfile Explained

> **Line-by-Line Breakdown of Our Multi-Stage Dockerfile**

This document explains every line of our Dockerfile, which uses multi-stage builds to create optimized images for both development and production.

---

## Table of Contents

1. [Overview](#overview)
2. [Multi-Stage Builds](#multi-stage-builds)
3. [Stage 1: Base Image](#stage-1-base-image)
4. [Stage 2: Dependencies](#stage-2-dependencies)
5. [Stage 3: Development](#stage-3-development)
6. [Stage 4: Production](#stage-4-production)
7. [Building and Running](#building-and-running)

---

## Overview

Our Dockerfile uses **multi-stage builds** to create:

1. A **development** image with all dev tools
2. A **production** image that's smaller and more secure

```
┌─────────────────────────────────────────────────────────────────────────┐
│                    Multi-Stage Build Flow                                │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │  Stage: base                                                     │    │
│  │  • Python 3.11 slim                                             │    │
│  │  • Environment variables                                        │    │
│  │  • Non-root user                                                │    │
│  └────────────────────────────┬────────────────────────────────────┘    │
│                               │                                          │
│                               ▼                                          │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │  Stage: dependencies                                             │    │
│  │  • System packages (gcc, libpq)                                 │    │
│  │  • Python packages from requirements.txt                        │    │
│  └────────────────────────────┬────────────────────────────────────┘    │
│                               │                                          │
│               ┌───────────────┴───────────────┐                         │
│               │                               │                         │
│               ▼                               ▼                         │
│  ┌────────────────────────────┐  ┌────────────────────────────┐         │
│  │  Stage: development        │  │  Stage: production          │         │
│  │                            │  │                            │         │
│  │  + Dev tools (pytest, etc) │  │  - No dev tools            │         │
│  │  + Hot-reload              │  │  - Gunicorn server         │         │
│  │  + Flask dev server        │  │  - Health check            │         │
│  │                            │  │  - Smaller image           │         │
│  └────────────────────────────┘  └────────────────────────────┘         │
│                                                                          │
│  docker build --target development  docker build --target production    │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## Multi-Stage Builds

### What Are Multi-Stage Builds?

Multi-stage builds let you use multiple `FROM` statements in one Dockerfile. Each `FROM` starts a new "stage" that can:

-   Build on previous stages
-   Be targeted independently
-   Share artifacts

### Why Use Multi-Stage?

| Without Multi-Stage            | With Multi-Stage             |
| ------------------------------ | ---------------------------- |
| One huge image with everything | Separate dev and prod images |
| Dev tools in production (bad)  | Only what's needed per stage |
| ~1GB+ image                    | ~200MB production image      |
| One Dockerfile per environment | One Dockerfile for all       |

---

## Stage 1: Base Image

```dockerfile
# =============================================================================
# Base Image
# =============================================================================
# Using Python 3.11 slim for smaller image size while maintaining compatibility
FROM python:3.11-slim as base
```

**Explanation:**

-   `FROM python:3.11-slim` - Start from official Python image
    -   `3.11` - Specific Python version (pinned for reproducibility)
    -   `slim` - Minimal Debian variant (~150MB vs ~1GB for full image)
-   `as base` - Name this stage "base" for later reference

### Why slim?

| Variant  | Size   | Contains                                      |
| -------- | ------ | --------------------------------------------- |
| `full`   | ~1GB   | Everything, including compilers               |
| `slim`   | ~150MB | Minimal packages                              |
| `alpine` | ~50MB  | Alpine Linux (can cause compatibility issues) |

---

```dockerfile
# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1
```

**Explanation:**

| Variable                        | Value | Purpose                                       |
| ------------------------------- | ----- | --------------------------------------------- |
| `PYTHONDONTWRITEBYTECODE`       | `1`   | Don't create `.pyc` files (smaller image)     |
| `PYTHONUNBUFFERED`              | `1`   | Print output immediately (better Docker logs) |
| `PIP_NO_CACHE_DIR`              | `1`   | Don't cache pip downloads (smaller image)     |
| `PIP_DISABLE_PIP_VERSION_CHECK` | `1`   | Skip pip version check (faster builds)        |

---

```dockerfile
# Create non-root user for security
RUN groupadd --gid 1000 appgroup \
    && useradd --uid 1000 --gid appgroup --shell /bin/bash --create-home appuser
```

**Explanation:**

Security best practice: Don't run as root!

-   `groupadd --gid 1000 appgroup` - Create a group
-   `useradd --uid 1000 --gid appgroup ...` - Create a user in that group

If container is compromised, attacker has limited permissions.

---

```dockerfile
# Set working directory
WORKDIR /app
```

**Explanation:**

-   All subsequent commands run in `/app`
-   Like `cd /app` but also creates the directory
-   All `COPY` commands are relative to this

---

## Stage 2: Dependencies

```dockerfile
# =============================================================================
# Dependencies Stage
# =============================================================================
FROM base as dependencies
```

**Explanation:**

-   `FROM base` - Start from our base stage
-   `as dependencies` - Name this stage "dependencies"

---

```dockerfile
# Install system dependencies for psycopg2
RUN apt-get update && apt-get install -y --no-install-recommends \
    libpq-dev \
    gcc \
    && rm -rf /var/lib/apt/lists/*
```

**Explanation:**

| Package     | Why Needed                               |
| ----------- | ---------------------------------------- |
| `libpq-dev` | PostgreSQL client library (for psycopg2) |
| `gcc`       | C compiler (psycopg2 has C extensions)   |

-   `--no-install-recommends` - Only install required packages
-   `rm -rf /var/lib/apt/lists/*` - Clean up to reduce image size

**Best Practice:** One `RUN` command to reduce layers.

---

```dockerfile
# Copy requirements first for better caching
COPY requirements.txt .
```

**Explanation:**

Copy ONLY `requirements.txt` first, not the entire codebase.

**Why?** Docker caches each layer. If `requirements.txt` doesn't change, the next `pip install` layer is cached, even if your code changes.

```
Code change → Only rebuild: COPY . and after
requirements.txt change → Rebuild: pip install and after
```

---

```dockerfile
# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt
```

**Explanation:**

Install all Python packages. This layer is cached if `requirements.txt` is unchanged.

---

## Stage 3: Development

```dockerfile
# =============================================================================
# Development Stage
# =============================================================================
FROM dependencies as development
```

**Explanation:**

Builds on dependencies stage, adds development-specific setup.

---

```dockerfile
# Install development dependencies
RUN pip install --no-cache-dir pytest pytest-cov black isort flake8 mypy
```

**Explanation:**

Development tools NOT in `requirements.txt`:

| Tool         | Purpose          |
| ------------ | ---------------- |
| `pytest`     | Test runner      |
| `pytest-cov` | Coverage reports |
| `black`      | Code formatter   |
| `isort`      | Import sorter    |
| `flake8`     | Linter           |
| `mypy`       | Type checker     |

---

```dockerfile
# Copy application code
COPY --chown=appuser:appgroup . .
```

**Explanation:**

-   `COPY . .` - Copy entire project into container
-   `--chown=appuser:appgroup` - Set ownership to our non-root user

---

```dockerfile
# Switch to non-root user
USER appuser
```

**Explanation:**

All subsequent commands and the running container use `appuser`, not root.

---

```dockerfile
# Expose port
EXPOSE 5500
```

**Explanation:**

Documentation that the container listens on port 5500. Doesn't actually publish the port (that's done with `-p` or in docker-compose).

---

```dockerfile
# Development command with hot-reload
CMD ["flask", "run", "--host=0.0.0.0", "--port=5500", "--reload"]
```

**Explanation:**

Default command when container starts:

-   `flask run` - Use Flask's development server
-   `--host=0.0.0.0` - Listen on all interfaces (required for Docker)
-   `--port=5500` - Our chosen port
-   `--reload` - Auto-restart on code changes

---

## Stage 4: Production

```dockerfile
# =============================================================================
# Production Stage
# =============================================================================
FROM dependencies as production
```

**Explanation:**

Also builds on dependencies, but skips dev tools from the development stage.

---

```dockerfile
# Copy application code
COPY --chown=appuser:appgroup . .
```

Same as development.

---

```dockerfile
# Remove unnecessary files for production
RUN rm -rf tests/ docs/ *.md .git* .env.example
```

**Explanation:**

Remove files not needed in production:

| Removed        | Why                           |
| -------------- | ----------------------------- |
| `tests/`       | Tests don't run in production |
| `docs/`        | Documentation not needed      |
| `*.md`         | README, etc. not needed       |
| `.git*`        | Git history not needed        |
| `.env.example` | Template file not needed      |

---

```dockerfile
# Create logs directory
RUN mkdir -p logs && chown appuser:appgroup logs
```

**Explanation:**

Create the logs directory with correct permissions before switching to non-root user.

---

```dockerfile
# Switch to non-root user
USER appuser
```

Same as development - security best practice.

---

```dockerfile
# Expose port
EXPOSE 5500
```

Same as development.

---

```dockerfile
# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import urllib.request; urllib.request.urlopen('http://localhost:5500/health')" || exit 1
```

**Explanation:**

Docker periodically checks if the container is healthy:

| Option           | Value | Meaning                         |
| ---------------- | ----- | ------------------------------- |
| `--interval`     | 30s   | Check every 30 seconds          |
| `--timeout`      | 10s   | Fail if check takes > 10s       |
| `--start-period` | 5s    | Wait 5s before first check      |
| `--retries`      | 3     | Mark unhealthy after 3 failures |

The check: Make HTTP request to `/health` endpoint.

---

```dockerfile
# Production command using gunicorn
CMD ["gunicorn", "--bind", "0.0.0.0:5500", "--workers", "4", "--threads", "2", "run:app"]
```

**Explanation:**

Production uses Gunicorn instead of Flask's dev server:

| Option      | Value          | Meaning                    |
| ----------- | -------------- | -------------------------- |
| `--bind`    | `0.0.0.0:5500` | Listen on all interfaces   |
| `--workers` | `4`            | 4 worker processes         |
| `--threads` | `2`            | 2 threads per worker       |
| `run:app`   | `run:app`      | Import `app` from `run.py` |

**Why Gunicorn?**

| Flask Dev Server         | Gunicorn                   |
| ------------------------ | -------------------------- |
| Single-threaded          | Multi-worker, multi-thread |
| Not meant for production | Production-grade           |
| No process management    | Handles crashes gracefully |

---

## Building and Running

### Build Development Image

```bash
docker build --target development -t myapp:dev .
```

### Build Production Image

```bash
docker build --target production -t myapp:prod .
```

### Run Development

```bash
docker run -p 5500:5500 -v .:/app myapp:dev
```

### Run Production

```bash
docker run -p 5500:5500 \
  -e DATABASE_URL=postgresql://... \
  -e SECRET_KEY=... \
  myapp:prod
```

### Image Size Comparison

```bash
$ docker images
REPOSITORY  TAG   SIZE
myapp       dev   450MB   # Has dev tools
myapp       prod  280MB   # Leaner, no tests/docs
```

---

## Summary

### Key Concepts

1. **Multi-stage builds** reduce image size and separate concerns
2. **Layer caching** speeds up builds (copy requirements first!)
3. **Non-root user** improves security
4. **Development stage** has dev tools and hot-reload
5. **Production stage** uses Gunicorn and health checks

### Complete Dockerfile

```dockerfile
# Base: Python + env vars + user
FROM python:3.11-slim as base
ENV PYTHONDONTWRITEBYTECODE=1 ...
RUN groupadd ... && useradd ...
WORKDIR /app

# Dependencies: System packages + Python packages
FROM base as dependencies
RUN apt-get install libpq-dev gcc ...
COPY requirements.txt .
RUN pip install -r requirements.txt

# Development: Add dev tools
FROM dependencies as development
RUN pip install pytest black isort flake8
COPY --chown=appuser:appgroup . .
USER appuser
CMD ["flask", "run", "--reload", ...]

# Production: No dev tools, Gunicorn
FROM dependencies as production
COPY --chown=appuser:appgroup . .
RUN rm -rf tests/ docs/ ...
USER appuser
HEALTHCHECK ...
CMD ["gunicorn", ...]
```

---

## Next Steps

-   **[7.4 Docker Compose](./7.4_docker_compose.md)** - Multi-container orchestration
-   **[7.8 Production Deployment](./7.8_production_deployment.md)** - Deployment considerations

---

> **Related Documentation:**
>
> -   [Dockerfile](../../Dockerfile)
> -   [docker-compose.yml](../../docker-compose.yml)
